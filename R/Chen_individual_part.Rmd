---
title: "Chen Individual Part"
output: pdf_document
---

```{r, echo=FALSE}
UM <- read.csv("C:/Users/User/Downloads/New folder/UM.csv")
UM2 = na.omit(UM[,c("Amount", "Year", "Organisation.Type", "Area", "Classified")])
UML = subset(UM2, Year > 1960 & Year < 2009)
```

We will be using the $\log$ link function for all our general linear model, since a log link function will always guarantee a positive mean result. When analyzing the amount of money, there will only be positive results. First, we start off with a Gaussian distribution shown below:

```{r, eval=FALSE}
## GLM Gaussian fits with log link function
GaussianAmount = glm(log(Amount) ~ Year + Organisation.Type + Area + Classified, 
                     family = gaussian(link = "log"), data=UML)
qqnorm(residuals(GaussianAmount), pch=16, ylab="GaussianResiduals", xlab = "Amount", 
       main="Gaussian")
qqline(residuals(GaussianAmount))
plot(residuals(GaussianAmount) ~ fitted(GaussianAmount), pch=16, ylab="GaussianResiduals", 
     xlab="Fitted Means", main="Gaussian")
## Shapiro-Wilks test for normality how do i work out sd for the GLM model in R?
##shapiro.test(rnorm(GaussianAmount, mean = 0, sd = 3500000))
```

![Description Pie](CGaussian1.png)
![Description Pie](CGaussian2.png)

Remember that GLM transforms the data to make the response and variables linearly related regardless of whether the data within them follows a normal distribution. Hence the residual of any valid GLM model should look normally distributed regardless of its distribution. However it is not the case for the Gaussian model, residual of the Gaussian model first shows heavy skewing to the right. To reduce the right skewness we use the log transformation of the response(Amount). After take the log transformation of the response(Amount) there was still heavy right skewness, indicate that the residual of Gaussian model is not normally distributed.

(Shapiro-Wilks test P-value < 0.05 reject normality, what ever the P-value in percentage is the likelihood of normality.)

Non-constant variance was another problem for this fit. For a valid regression analysis,you need to have a constant variance of the error terms, and they must have a mean of zero. The residual of Gaussian model appear to increase then decrease across the fitted values, so this indicate the variance in the error terms has a non-constant variance.

The conclusion is that the Gaussian distribution was not a valid model, let's try the next distribution in the exponential family, the Poisson distribution:

```{r, eval=FALSE}
## GLM Poisson fits with log link function
PoissonAmount = glm(log(Amount) ~ Year + Organisation.Type + Area + Classified, 
                    family = poisson(link="log"),data=UML)
qqnorm(residuals(PoissonAmount), pch=16, ylab="PoissonResiduals", xlab = "Amount", 
       main="Poisson")
qqline(residuals(PoissonAmount))
plot(residuals(PoissonAmount) ~ fitted(PoissonAmount), pch=16, ylab="PoissonResiduals", 
     xlab="Fitted Means", main="Poisson")
```

![Description Pie](CPoisson1.png)
![Description Pie](CPoisson2.png)

The residual the Poisson fit first shows heavy skewing to the right. To reduce the right skewness we use the log transformation of the response(Amount). After take the log transformation of the response(Amount) there was still right skewness, indicate that the residual of Poisson model is not normally distributed.

Also the residual of the the Gama model appear to increase then decrease across the fitted values, hence this indicate the variance in the error terms has a non-constant variance., which indicate the variance in the error terms was not constant.

The conclusion was that the Poisson model was not a valid model either, let's try the next distribution in the exponential family, the Gamma distribution:

At first the Gamma model did not converge, but the log transformation of the response(Amount) magically fixed the converge issues.
```{r, eval=FALSE}
## GLM Gamma fits with log link function
GammaAmount = glm(log(Amount) ~ Year + Organisation.Type + Area + Classified , 
                  family = Gamma(link = "log"), data=UML)
qqnorm(residuals(GammaAmount), pch=16, ylab="GammaResiduals", xlab = "Amount", 
       main="Gamma")
qqline(residuals(GammaAmount))
plot(residuals(GammaAmount) ~ fitted(GammaAmount), pch=16, ylab="GammaResiduals", 
     xlab="Fitted Means", main="Gamma")
```

![Description Pie](CGamma1.png)
![Description Pie](CGamma2.png)

The residual of the Gamma model was not normally distributed. also The residual of the Gama model appear to increase then decrease across the fitted values, therefore this indicate the variance in the error terms has a non-constant variance.

The conclusion was that the Gamma model was not a valid model either, let's try the next distribution in the exponential family, the IverseGaussian distribution.


At first the IverseGaussian model did not converge, but the log transformation of the response(Amount) magically fixed the converge issues.

```{r, eval=FALSE}
## GLM IverseGaussian fits with log link function
InverseGaussianAmount = glm(log(Amount) ~ Year + Organisation.Type + Area + Classified ,
                            family = inverse.gaussian(link = "log"), data=UML)
qqnorm(residuals(InverseGaussianAmount), pch=16, ylab="InverseResiduals", xlab = "Amount",
       main="InverseGaussian")
qqline(residuals(InverseGaussianAmount))
plot(residuals(InverseGaussianAmount) ~ fitted(InverseGaussianAmount), pch=16, 
     ylab="InverseResiduals", xlab="Fitted Means", main="InverseGaussian")
```

![Description Pie](CInverseGaussian1.png)
![Description Pie](CInverseGaussian2.png)

The residual of the InverseGaussianAmount model was not normally distributed. Also The residual of the InverseGaussianAmount model appear to  decrease across the fitted values, therefore this indicate the variance in the error terms has a non-constant variance.

The conclusion was that the InverseGaussianAmount model was not a valid model either.

Although binomial distribution is part of the exponential family, but it is a discrete probability distribution.Hence it was not suited to model amount of money which is continuous. After all those attempts we were only left with the Tweedis distribution in the exponential family for GLM modelling.

The Tweedis family of distributions has defined variance function but with no closed form probability density function(except in special cases). It use in GLM's  requires selection of two parameters. A Power in link function and a power in variance function.

The Link function for Tweedies distribution:
$$\mu^q = X\beta$$
By convention the $\log$ link is power (q) of zero in the Tweedies link function.
The The variance function for Tweedies distribution:
$$Var(Y) = \mu^p$$
After take the log transformation of the response(Amount) variance function power (p) can be up to 10 tested.(note 7 made a big difference)
```{r, eval=FALSE}
### It requires the statmod package to run the Tweedie GLM
require(statmod) 
TweedieAmount = glm(log(Amount) ~ Year + Organisation.Type + Area + Classified
                    ,family=tweedie(link.power=0, var.power=4), data=UML)
qqnorm(residuals(TweedieAmount), pch=16, ylab="TweedieResiduals", xlab = "Amount", 
       main="Tweedie")
qqline(residuals(TweedieAmount))
plot(residuals(TweedieAmount) ~ fitted(TweedieAmount), pch=16, ylab="TweedieResiduals", 
     xlab="Fitted Means", main="Tweedie")
```

![Description Pie](CTweedie1.png)
![Description Pie](CTweedie2.png)


Again the residual of the Tweedie model was not normally distributed. Also The residual of the Tweedie model appear to  decrease across the fitted values, therefore this indicate the variance in the error terms has a non-constant variance.

The conclusion was that the Tweedie model was not a valid model either. After have attempted all distributions within the exponential family for the GLM model and failed to come up with a valid model. We conclude that GLM may not be right for this data set.By this stage, it was too late to try something else, except The  simple linear regression.

Around the same time Anjali discovered something significant is affecting the original data that we have not taken into account in fitting the model.
```{r, eval=FALSE} 
plot(residuals(GaussianAmount) ~ UML$Year, pch=16, ylab="GaussianResiduals", 
     xlab="Year",  main = "Trend in Residuals")
```

This plot shows that the curve increases with the variable 'Year', indicating that there may be a polynomial relationship between year and the data. Therefore fitting the Normal model with polynomial transformed variable poly(Year,4) and poly(Classified,4) may help to find a valid model. The number four is the power of the polynomial transformation, which is the power ofpolynomial transformation that produced best result.

```{r}
LogNormalAmount = lm(log(Amount) ~ poly(Year,4) + Organisation.Type + Area 
                     + poly(Classified,4), data = UML)
qqnorm(residuals(LogNormalAmount), pch=16, ylab="LogNormalAmountResiduals", 
       xlab = "Amount", main="LogNormal")
qqline(residuals(LogNormalAmount))
plot(residuals(LogNormalAmount) ~ fitted(LogNormalAmount), pch=16, 
     ylab="LogNormalAmountResiduals", xlab="Fitted Means", main="LogNormal")
##shapiro.test(rnorm(GaussianAmount, mean = 0, sd = 2))
```

The log transformation of the response(Amount) with  with polynomial transformed variable poly(Year,4) and poly(Classified,4) was the best model we could produce. The residual may still look not normally distributed, but it was better than any other GLM model.
Also there was no trend in the residual, so this indicate variance in the error terms has a constant variance. 

This was still far from a good fitted model. However due to time constrain this was the best we could do. Below is some conclusion base on this model:

```{r}
anova(LogNormalAmount, test = "LRT")
```

Analysis of Variance shows that all variables are significant with almost zero P-value.

Residual standard error: 0.8349 on 287871 degrees of freedom
Multiple R-squared:  0.154,	Adjusted R-squared:  0.1538 
F-statistic: 873.5 on 60 and 287871 DF,  p-value: < 2.2e-16

Adjusted R-squared of 0.1538 suggest the model is only explains 15% of the variability of the response data around its mean.  Hence this model is not good enough for prediction.
