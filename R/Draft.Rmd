
---
title: "A GLM-based method for investigating Unclaimed Money"
author: "Anjali Sharma, Chen Zhong. Supervisor: Glenn Stone"
date: '`r Sys.Date()`'
output:
  pdf_document:
    toc: yes
    number_sections: true
---

\newpage

# Introduction

This research takes an in-depth look at both the monetary value and the number of accounts containing unclaimed money across NSW.
Unclaimed money is the money held by the NSW state government that is given by an entity but remained uncollected by the recipient for some amount of time.
The period of inactivity has been defined as 7 years for accounts held before December 2012, 3 years for accounts held between December 2012 and May 2015, and 7 years for those held after May 2015.

Questions looking to be answered are: 

* What variables affect the amount of unclaimed money, as well as the number of accounts?
* Are any organization types correlated with frequency or amount of unclaimed money?
    + i.e. Financial Services.
    + i.e. Insurance.
    + i.e. Government.
    + i.e. Utility.
    + i.e. Mortgage Lending etc.
* Is inflation different across different areas?
    + i.e. Postcode
    + i.e. Area
    + i.e. Country (having unclaimed money from Australian institution)

## Why research unclaimed money?
Unclaimed Money is a public data set that has attracted little interest due to its lack of profitability for those without a claim to any of the money. 

Some analysis takes place through businesses, such as AURFS, which locate claimants and offer claiming services in exchange for a percentage of the claim. However, this ignores the vast amount of money held in small amounts across many accounts. 

ASIC is tasked with locating and informing claimants of monies but have expressed lack of resources and overwhelming number of accounts due to law changes.

## Approach
Data is available for unclaimed money for 380,671 accounts, going back to the year 1900. Methodology  involves data visualisation using Tableau, a drag and drop tool used for visual exploration, as well as R for merging, cleaning, sorting and GLM analysis, reproducing useful visualisations in code, and producing the final report using R Markdown. 

* The individual parts of the project are the modelling for the amounts (Chen) and the modelling for the number of accounts (Anjali)
    + (Anjali) Counting accounts means weighting areas by their population to obtain meaningful frequencies
    + (Anjali) ...as well as using a zero-truncated Poisson model to account for the fact that our data only takes into account the ones with missing money.
    + (Chen) Amounts requires working out the distribution it has with each variable and using the appropriate link function to create a meaningful model.
    + (Chen) Finding the right distribution is going to be a challenge due to the amount of distributions covered by GLM and their similarity.

### Extracting Postcodes using regex function
Data collation has so far involved file conversion, merging the 26 alphabetical files into one, and extracting postcodes using a regex function The regex pattern was sourced using Australia Post postcode area definitions. PO Box and Locked Bag numbers were being included in the regex, therefore all 4 digits numbers after the words PO Box or Locked Bag had to be removed before extracting the data.

Data thrown out was defined as a sequence of 4 digits arriving after the word "box" or "bag" regardless of letter case. The regex pattern to define the postcode is a sequence of or-statements, with one statement for each state of territory. The boundaries of each digit are defined between square brackets, with curly brackets indicating the number of time to repeat the last square bracket's contents. A loop was used to write the outcome of the pattern to a new variable:

```{r, eval=FALSE}
#Duplicate addresses
address = UM$Owner.Address

#Chuck out PO Boxes
address = gsub("box [0-9][0-9][0-9][0-9]", "", address, ignore.case = TRUE)
#Chuck out Locked Bags
address = gsub("bag [0-9][0-9][0-9][0-9]", "", address, ignore.case = TRUE)

#Pattern for extracting postcodes (line-break for printing only)
AU <- "(0[289][0-9]{2})|([1345689][0-9]{3})|(2[0-8][0-9]{2})|(290[0-9])|
       (291[0-4])|(7[0-4][0-9]{2})|(7[8-9][0-9]{2})"

#Identifies AU Postcode
AU <- ifelse(grepl(AU, UM$Owner.Address), 1, 0)
                
#Prints AU Postcode
x = regexpr(AU, address)
UM$Postcode <-  substring(address, x, x + attr(x, "match.length") - 1)
print(UM$Postcode)

#Creates new file with newly extracted data
write.csv(UM, file = "UMPCs.csv")

#Displays addresses according to postcode extraction

#If no postcode found, prints address
ifelse(UM$Postcode == "", as.character(UM$Owner.Address), "") 

#If postcode found, prints address
ifelse(UM$Postcode == "", "", as.character(UM$Owner.Address)) 
```

\newpage

### Classifying Postcodes into categories
Postcodes needed to be categorised into larger areas to allow sufficient data in each of the categories to facilitate analysis of the data overall. The postcode ranges were sourced online:

Area | Postcode Range
-----|---------------------------------------------------------------
Canberra CBD |	2600, 2601, 2610
Canberra |	2601 - 2609
Rest of ACT |	2611 - 2620
Sydney CBD |	1100 - 1299, 2000, 2001, 2007, 2009
Sydney Metro |	2002 - 2006, 2008, 2010 - 2234
Riverina Area |	2640 - 2660
Wollongong |	2500 - 2534
Newcastle |	2265 - 2333
Northern Rivers |	2413 - 2484
Rest of NSW |	2235 - 2412, 2485 - 2999
Melbourne CBD |	3000 - 3006, 3205, 8000 - 8399
Melbourne Metro |	3007 - 3204, 3206, 3207
Rest of VIC |	3208 - 3999
Brisbane CBD |	4000, 4001, 4003, 9000 - 9015
Brisbane Metro |	4002, 4004 - 4207, 4300 - 4305, 4500 - 4519
Gold Coast |	4208 - 4287
Sunshine Coast |	4550 - 4575
Rest of QLD |	4288 - 4299, 4306 - 4499, 4520 - 4549, 4576 - 4999
Adelaide CBD |	5000, 5001, 5004, 5005, 5810, 5839, 5880 - 5889
Adelaide Metro |	5002, 5003, 5006 - 5199
Rest of SA |	5200 - 5749, 5825 - 5854
Perth CBD |	6000, 6001, 6004, 6827, 6830 - 6832, 6837 - 6849
Perth Metro |	6002, 6003, 6005 - 6199
Rest of WA |	6200 - 6826, 6828, 6829, 6833 - 6836, 6850 - 6999
Hobart CBD |	7000, 7001
Hobart Metro |	7002 - 7099 
Rest of TAS |	7100 - 7999
Darwin Metro |	0800 - 0832
Rest of NT |	0833 - 0899

\newpage
We classified postcodes by creating a function with a number of if-statements:

```{r, eval=FALSE}
PC2Area = function(PC) {
  if(is.na(PC))                                                                                                      
    return("Unknown")
  if( PC %in% c(2600, 2601, 2610) )                                                                               
    return("Canberra CBD")
  if( PC >= 2601 && PC <= 2609 )                                                                                  
    return("Canberra Metro")
  if( PC >= 1100 && PC <= 1299 || PC %in% c(2000, 2001, 2007, 2009) )                                             
    return("Sydney CBD")
  if( PC >= 2002 && PC <= 2234 )                                                                                  
    return("Sydney Metro")
  if( PC >= 2640 && PC <= 2660 )                                                                                  
    return("Riverina Area")
  if( PC >= 2500 && PC <= 2534 )                                                                                  
    return("Wollongong")
  if( PC >= 2265 && PC <= 2333 )                                                                                  
    return("Newcastle")
  if( PC >= 2413 && PC <= 2484 || PC >= 2460 && PC <= 2465 || PC == 2450 )                                        
    return("Northern Rivers")
  if( PC >= 3000 && PC <= 3006 || PC == 3205 || PC >= 8000 && PC <= 8399 )                                        
    return("Melbourne CBD")
  if( PC >= 3000 && PC <= 3207 )                                                                                  
    return("Melbourne Metro")
  if( PC %in% c(4000, 4001, 4003) || PC >= 9000 && PC <= 9015 )                                                   
    return("Brisbane CBD")
  if( PC >= 4000 && PC <= 4207 || PC >= 4300 && PC <= 4305 || PC >= 4500 && PC <= 4519 )                          
    return("Brisbane Metro")
  if( PC >= 4208 && PC <= 4287 )                                                                                  
    return("Gold Coast")
  if( PC >= 4550 && PC <= 4575 )                                                                                  
    return("Sunshine Coast")
  if( PC %in% c(5000, 5001, 5004, 5005, 5810, 5839) || PC >= 5880 && PC <= 5889 )                                 
    return("Adelaide CBD")
  if( PC >= 5000 && PC <= 5119 )                                                                                  
    return("Adelaide Metro")
  if( PC %in% c(6000, 6001, 6004, 6827) || PC >= 6830 && PC <= 6832 || PC >= 6837 && PC <= 6849 )                 
    return("Perth CBD")
  if( PC >= 6000 && PC <= 6199 )                                                                                  
    return("Perth Metro")
  if( PC %in% c(7000, 7001) )                                                                                     
    return("Hobart CBD")
  if( PC >= 7002 && PC <= 7099 )                                                                                  
    return("Hobart Metro")
  if( PC >= 0800 && PC <= 0832 )                                                                                  
    return("Darwin Metro")
  if( PC >= 0200 && PC <= 0299 )                                                                                  
    return("ACT PO Box or LVR")
  if( PC >= 2600 && PC <= 2620 || PC >= 2900 && PC <= 2920 )                                                      
    return("Rest of ACT")
  if( PC >= 1000 && PC <= 1999 )                                                                                  
    return("NSW PO Box or LVR")
  if( PC >= 2235 && PC <= 2999 )                                                                                  
    return("Rest of NSW")
  if( PC >= 8000 && PC <= 8999 )                                                                                  
    return("VIC PO Box or LVR")
  if( PC >= 3208 && PC <= 3999 )                                                                                  
    return("Rest of VIC")
  if( PC >= 9000 && PC <= 9999 )                                                                                  
    return("QLD PO Box or LVR")
  if( PC >= 4208 && PC <= 4299  || PC >= 4306 && PC <= 4499  || PC >= 4520 && PC <= 4999 )                        
    return("Rest of QLD")
  if( PC >= 5800 && PC <= 5999 )                                                                                  
    return("SA PO Box or LVR")
  if( PC >= 5000 && PC <= 5799 || PC >= 5825 && PC <= 5854 )                                                      
    return("Rest of SA")
  if( PC >= 7800 && PC <= 7999 )                                                                                  
    return("TAS PO Box or LVR")
  if( PC >= 7100 && PC <= 7999 )                                                                                  
    return("Rest of TAS")
  if( PC >= 6800 && PC <= 6999 )                                                                                  
    return("WA PO Box or LVR")
  if( PC >= 6200 && PC <= 6999 )                                                                                  
    return("Rest of WA")
  if( PC >= 0900 && PC <= 0999 )                                                                                  
    return("NT PO Box or LVR")
  if( PC >= 0833 && PC <= 0899 )                                                                                  
    return("Rest of NT")
  return("XXXX")
}

## To check temporary variable 'Area' holds all results
Area = sapply(UM$Postcode, PC2Area)

## Shows first few unmatched postcodes
head(UM$Postcode[Area=="XXXX"])

## Write new column 'Area'
UM$Area = sapply(UM$Postcode, PC2Area)

write.csv(UM, file = "UM.csv")

```

\newpage

### Categorising Organisations
There are too many companies in the original data and their frequencies vary widely. Since we have no way to automatically categorise them, the most efficient method to analysis them is to categories top occurring percent of companies.
We created lists of top occurring companies and worked out the percentile of accounts each list of companies covered. We made the number of top companies increase in increments of 10.
```{r, echo=FALSE}
NumEntries = c(268, 276, 283, 289, 295, 299, 304, 307, 311, 314)
NumTopOrg = c(70, 80, 90, 100, 110, 120, 130, 140, 150, 160)
percentage = NumEntries/380
ORGSUM = data.frame(NumEntries, NumTopOrg, percentage)
print(ORGSUM)
```
Categories for the top 100 companies were collated by hand using company websites and information available on ASX (Australian Share Index). The sum of the number of accounts increased by about 1% for every 10 companies added above 100, also with diminishing return. whereas leading up to 100, the number of accounts was increasing by about 2%. We decided to use top 100 occurring companies because it covers 76% of the data. It is practical for the time we have.

```{r, eval=FALSE}
#Making a matrix for optimising organisation classification
NumEntries = c(268, 276, 283, 289, 295, 299, 304, 307, 311, 314)
NumTopOrg = c(70, 80, 90, 100, 110, 120, 130, 140, 150, 160)
percentage = NumEntries/380
ORGSUM = data.frame(NumEntries, NumTopOrg, percentage)
#Conclusion is top 100 organisations is most efficient way 
#to categorise large chunk of data for the time we have.

#Prints number of accounts covered by top 100 organistions
sum(head(sort(table(UM$Organisation.Name), decreasing = TRUE), 60))

#Prints top 100 organistions
xx = head(sort(table(UM$Organisation.Name), decreasing = TRUE), 100)

write.csv(names(xx), file="Top100.csv")
barplot(head(sort(table(UM$Organisation.Name), decreasing = TRUE), 100))
```

\newpage

To match the column 'Organisation.Name' in Unclaimed Money (UM) with the column 'Organisation.Type' in Company Category (CC), which was categorised by hand:

Organisation |	Type
-------------|------------------------------------------------------------------------
QANTAS AIRWAYS LTD|Airline
GRAINCORP LTD|Beverage and Food
GOODMAN FIELDER LTD|Beverage and Food
COCA-COLA AMATIL LTD|Beverage and Food
LION NATHAN LTD|Beverage and Food
USANA AUST PTY LTD|Beverage and Food
MACQUARIE UNI|Education
THE UNI OF NSW|Education
AMP LTD|Financial Services
AMP LTD/AMP|Financial Services
WESTPAC BANKING CORP|Financial Services
VEDA ADVANTAGE LTD|Financial Services
ING AUST LTD|Financial Services
AMERICAN EXPRESS AUST LTD|Financial Services
CAPITAL FIN AUST LTD|Financial Services
CHALLENGER LTD/CGF|Financial Services
CWEALTH SECURITIES LTD|Financial Services
ESANDA FIN CORP LTD|Financial Services
TOYOTA FIN AUST LTD|Financial Services
AMP GROUP FIN SERVS LTD|Financial Services
CHALLENGER LTD|Financial Services
TAB LTD|Gaming
TABCORP HLDGS LTD & TABCORP HLDGS LTD|Gaming
ARISTOCRAT LEISURE LTD|Gaming
OFFICE OF REAL EST SERVICES|Government
CITY OF SYDNEY|Government
PARRAMATTA CITY CNCL|Government
FAIRFIELD CITY CNCL & WOLLONDILLY SHIRE CNCL|Government
BORAL LTD|Industrial 
RINKER GROUP PTY LTD|Industrial 
OFFSET ALPINE PRINTING GROUP PTY LTD|Industrial 
ONESTEEL LTD|Industrial 
CSR LTD|Industrial 
BRAMBLES INDUSTS LTD|Industrial 
CSR LIMITED|Industrial 
INTOLL GROUP|Industrial 
MBF AUST LTD|Insurance
INS AUST GROUP|Insurance
INS AUST GROUP LTD|Insurance
INS AUST GROUP LTD/IAG|Insurance
GIO GEN LTD|Insurance
THE HOSPITALS CONTRIBUTION FUND OF AUST LTD|Insurance
QBE INS (AUST) LTD|Insurance
SUNCORP|Insurance
NIB HEALTH FUNDS|Insurance
ALLIANZ INS AUST LTD|Insurance
CWEALTH INS LTD|Insurance
ING IND FUND|Insurance
ACE INS LTD|Insurance
CGU INSURANCE LTD|Insurance
ECORP LTD|IT
APN NEWS & MEDIA LTD|Media Company
CNSLD MEDIA HLDGS LTD|Media Company
TEN NETWORK HLDGS|Media Company
FAIRFAX MEDIA LTD|Media Company
ARRIUM LTD|Mining
AUN|Mining
GENWORTH FIN MORTGAGE INS PTY LTD|Mortgage Lending
GALILEE SOLICITORS|Mortgage Lending
QBE LENDERS MORTGAGE INSCE LTD|Mortgage Lending
NATIONAL LENDING SOLUTIONS| Mortgage Lending
CAMBRIDGE CREDIT CORP LTD|Property Management
MIRVAC REAL EST INVEST TRUST|Property Management
GENERAL PROPERTY TRUST|Property Management
LEND LEASE GROUP/LLC|Property Management
MIRVAC REAL EST INVEST TRUST (FORMERLY MERIDIAN)|Property Management
LEND LEASE CORP LTD|Property Management
WESTFIELD GROUP|Property Management
WESTFIELD GROUP/WDC|Property Management
MIRVAC GROUP|Property Management
INVESTA PROPERTY GROUP|Property Management
STOCKLAND CORP LTD|Property Management
WOOLWORTHS LTD|Retailer
WOOLWORTHS LIMITED|Retailer
DAVID JONES LIMITED|Retailer
WOOLWORTHS LTD/WOW|Retailer
METCASH LTD|Retailer
AMP SUPER SAVINGS TRUST|SuperFund
AUST'N ELIGIBLE ROLLOVER FUND|SuperFund
SUPERTRACE ELIGIBLE ROLLOVER FUND|SuperFund
AMP ELIGIBLE ROLLOVER FUND|SuperFund
UNIVERSAL SUPER SCHEME FUND|SuperFund
STATE SUPER|SuperFund
BT FUNDS MGMT|SuperFund
CLUB PLUS SUPER PTY LTD|SuperFund
COLONIAL MUTUAL LIFE ASSUR LTD|SuperFund
AON ELIGIBLE ROLLOVER FUND|SuperFund
LEGAL & GEN SUPERTRACE|SuperFund
AUST PRIMARY SUPER FUND|SuperFund
SINGTEL OPTUS|Utility
ENERGY AUST (NCLE)|Utility
AUSGRID|Utility
THE AUSTRALIAN GAS LIGHT COMPANY|Utility
AGL ENERGY LTD|Utility
ORIGIN ENERGY LTD|Utility
ENERGY AUST|Utility
COUNTRY ENERGY|Utility
INTEGRAL ENERGY	|Utility
ORIGIN|Utility
JACK GREEN (INTNL) PTY LTD|Utility


### Adding population data for each area
We downloaded a file from ABS website (File name 3218.0 Regional Population Growth, Australia) which was released at 11:30 am 31/03/2015.  We used the latest data from 2014, and categorised the postcode into 21 areas.
We matched all 21 postcode areas to the corresponding ABS data:

PC AREA | ABS AREA | 2014 POP.
---------|----------|---------------------------
Canberra CBD | Total Canberra Inner City | 0 
Canberra | GREATER CANBERRA | 79183 
Rest of ACT | REST OF ACT | 306813 
Sydney CBD | Total Sydney Inner City | 203774 
Sydney Metro | GREATER SYDNEY | 4636854 
Riverina Area | Riverina Area | 158144 
Wollongong | Wollongong | 296845 
Newcastle | Newcastle | 368131 
Northern Rivers | Richmond tweed | 242116 
Rest of NSW | REST OF NSW | 1612608 
Melbourne CBD | Total Melbourne City | 122190 
Melbourne Metro  | GREATER MELBOURNE | 4318138 
Rest of VIC | REST OF VIC | 1401339 
Brisbane CBD | Total Brisbane Inner | 65542 
Brisbane Metro | GREATER BRISBANE | 2209018 
Gold Coast | Total Gold Coast | 560266
Sunshine Coast | Sunshine Coast | 335874 
Rest of QLD | REST OF QLD | 1869515 
Adelaide CBD | Total Adelaide City | 22690 
Adelaide Metro | GREATER ADELAIDE | 1281941 
Rest of SA | REST OF SA | 381083 
Perth CBD | Total Perth City | 108216 
Perth Metro | GREATER PERTH | 1912987 
Rest of WA | REST OF WA | 552186 
Hobart CBD | Total Hobart Inner | 50757 
Hobart Metro | GREATER HOBART | 168486 
Rest of TAS | REST OF TAS | 295519 
Darwin Metro | Total Darwin City | 26281 
Rest of NT | REST OF NT | 78412 


We  found the individual area population for the CBD of each state and territory in the ABS file and subtracted it from the total population of the corresponding state to uncover the presented population density values.

The aim is not to forecast any changes in population based on area, but to use the ratio of population between each area to gain perspective of how much the number of accounts depends on population or other factors. Therefore, population data is only needed for the one year, 2014. If there is time, we can use the ratios from the appropriate year corresponding to the year the account was classified as unclaimed. This would allow us to model the frequency of each area over time.


\newpage

# Statistical Theory

## Concept
GLM is a combination of a linear model, the link function, the distribution mean, and the dispersion parameter which is not always needed. The main difference is that linear models assume the distribution of errors is normal, whereas GLM can account for mildly non-normal error distributions.GLM transforms the data to make the response and variables linearly related regardless of whether that data within them follows a normal distribution. 

## Formation of Matricies

Equation for each observation of the response variable Y from 1 to n:

\begin{eqnarray*}
Y_{1}&=&\beta_{0}+\beta_{1}X_{11}+\dots+\beta_{p}X_{1p}+\varepsilon_{1} \\
Y_{2}&=&\beta_{0}+\beta_{1}X_{21}+\dots+\beta_{p}X_{2p}+\varepsilon_{2} \\
Y_{3}&=&\beta_{0}+\beta_{1}X_{31}+\dots+\beta_{p}X_{3p}+\varepsilon_{3} \\
\vdots \\
Y_{n}&=&\beta_{0}+\beta_{1}X_{n1}+\dots+\beta_{p}X_{np}+\varepsilon_{n} \\
\end{eqnarray*}

Turn these simultaneous equations into matrix form:

\[
\begin{bmatrix}
    Y_{1} \\
    Y_{2} \\
    Y_{3} \\
    \vdots\\
    Y_{n} \\     
\end{bmatrix}
=
\begin{bmatrix}
    1 & X_{11} & \dots & \dots & \dots & X_{1p} \\
    1 & X_{21} & \dots & \dots & \dots & X_{2p} \\
    1 & X_{31} & \dots & \dots & \dots & X_{3p} \\
    \vdots & \vdots & \vdots & \vdots & \ddots & \vdots \\
    1 & X_{n1} & \dots & \dots & \dots & X_{np} \\
\end{bmatrix}
\begin{bmatrix}
    \beta_{0} \\
    \beta_{1} \\
    \beta_{2} \\
    \vdots \\
    \beta_{p} \\
\end{bmatrix}
+
\begin{bmatrix}
    \varepsilon_{1} \\
    \varepsilon_{2} \\
    \varepsilon_{3} \\
    \vdots \\
    \varepsilon_{n} \\
\end{bmatrix}
\]

Turn these matrix into a single equation:
  $$ Y = X\beta + \varepsilon $$

Here, Y is the matrix of each observation of the response variable, X is the matrix of each of the predictor variables which explain the response variable, $\beta$ is the matrix of the coefficients which define the contribution of each predictor variable and $\varepsilon$ is the matrix of the difference between the observed data and predicted model.

The expected value of Y, also known as $\mu$, can be though of as a linear combination of $X\beta$.

$$ \mathbf{E}(Y)=\mu=g^{-1}(X\beta) $$

It is this $g^{-1}()$ function that is comprised of the link function that is chosen based on the distribution of the data, and ultimately, the best fitting link function.

## Exponential family
GLM handles distributions that exist in the exponential family. In this way, GLM can be used to capture mildly non-linear data structures.The exponential family of statistical models that GLM unifies takes the following general form:

$$ f(y | \theta,\phi)=exp(\frac{y\theta-b(\theta)}{a(\phi)}+c(y,\phi)) $$

$\theta$ is the canonical parameter and represents the location while $\phi$ is the dispersion parameter and represents the scale.

The exponential family distribution has mean and variance:

$$ \mathbf{E}(Y)=\mu=b'(\theta) $$
$$ \mathbf{Var}(Y)=b"(\theta)a(\phi) $$

The variance ($\mathbf{Var}(Y)$) is a product of the functions of $\theta$ and $\phi$. This is a requirement for the mean ($\mathbf{E}(Y)$) to be a function of $\theta$.

The Binomial and Poisson distributions are useful examples of the exponential distribution family that may be relevant to our project. 

These are the major distributions and their canonical link functions. 

Family|C.Link|Variance Function
:-------:|:------:|:-------------------------------------:
$Normal$|$\mu$|$1$
$Poisson$|$\log(\mu)$|$\mu$
$Binomial$|$\log(\frac{\mu}{1-\mu})$|$\frac{\mu}{1-\mu}$
$Gamma$|$\frac{1}{\mu}$|$\mu^2$
$Inverse Gaussian$|$\frac{1}{\mu^2}$|$\mu^3$

\newpage

## Binomial Distribution
For a binomial distribution, the canonical link function is derived as follows:

\begin{eqnarray*}
f(y | \theta,\phi)=\binom{n}{y}\mu^y(1-\mu)^{n-y}
&=&exp(\log\binom{n}{y}\mu^y(1-\mu)^{n-y})) \\
&=&exp(\log\binom{n}{y}+\log(\mu^y)+\log((1-\mu)^{n-y})) \\
&=&exp(\log\binom{n}{y}+y\log(\mu)+(n-y)\log(1-\mu)) \\
&=&exp(\log\binom{n}{y}+y\log(\mu)+n\log(1-\mu)-y\log(1-\mu)) \\
&=&exp(\log\binom{n}{y}+y\log(\frac{\mu}{1-\mu})+n\log(1-\mu)-y\log(1-\mu))
\end{eqnarray*}

Therefore, the link function is 
$$ \theta=\log(\frac{\mu}{(1-\mu)}) $$

Note: In statistics, $\log$ is base $e$ and $\mu$ is the mean.

For binomial distribution in GLM, $\mathbf{p}$ is the probability of success. We define the response as odds rather than count.  

In the binomial distribution, odds are sometimes a better scale than probability to represent chance. A model might predict that an increase in population of 100 people makes it two times more likely to increase the number of accounts by 1. But it cannot simply double the probability value (e.g.60% become 120%) since this would require the existence of probabilities more than 100%. Rather, it is the odds that are doubling, from 2:1 odds to 4:1 odds. 

$$ Odds = \frac{Proportion Of Successes}{Proportion Of Failures} = \frac{p}{1-p} $$ 
$$ Odds = \frac{p}{1-p} $$

This link function allows the mean $\mu$  to be converted into odds. to ensure $0\leq\mathbf{p}\leq1$ we use $\log(\frac{\mu}{(1-\mu)})$

\newpage

## Poisson Distribution
For a poisson distribution, the link function is derived as follows: 

\begin{eqnarray*}
f(y | \theta,\phi)=\frac{e^{-\mu}\mu^y}{y!}
&=&exp(\log(\frac{e^{-\mu}\mu^y}{y!})) \\
&=&exp(\log(e^{-\mu})+\log(\mu^y)-\log(y!)) \\
&=&exp(-\mu+\log(\mu^y)-\log(y!)) \\
&=&exp(\log(\mu^y)-\mu+-\log(y!)) \\
&=&exp(y\log(\mu)-\mu+-\log(y!))
\end{eqnarray*}

Therefore, the link function is 
$$\theta=\log(\mu) $$

Note: In statistics, $\log$ is base $e$ and $\mu$ is the mean. 

This link function is the most natural choice for the Poisson distribution, since the mean $\mu$ for Poisson is always above zero. The obvious choice is $\mu=e^{X\beta}$. Writing the equation for the link function as a function of the mean $\mu$ gives $X\beta=\log(\mu)$ to make certain that the mean $\mu$ is positive. This will have the effect of making addition within $X$ affect $\mu$ multiplicatively.

If a model predicted that a decrease of 1000 in population for an area would lead to 10 fewer accounts, this model would not generalise well in areas with <10 accounts. For example, if an area with <10 accounts decreased in population by 1000, it would then have <0 accounts. This is not possible, and realistically, this implies the relationship between population and number of accounts is a ratio rather than a linear relationship. This is where the $\log()$ link function is useful. An increase in 1000 population would lead to a doubling of the number of accounts, and population decrease would lead to a fraction of the number of accounts. This creates an exponential-response model, one of which, is the Poisson distribution model.

It is important to note that the link functions mentioned are the canonical link functions, and are not the only option, or always the best option. The canonical link is the most obvious choice, for the corresponding distribution, mathematically and computationally. Ultimately, the link function used to create our final model will be chosen based on the best fit with our data.



\newpage

# References

Apps08.osr.nsw.gov.au,. 'NSW Office Of State Revenue'. N.p., 2015. Web. 30 July 2015.

Faraway, Julian James. Extending Linear Models With R. Boca Raton, Fla.: Chapman & Hall/CRC, 2006. Print.

Osr.nsw.gov.au,. 'About Unclaimed Money | Office Of State Revenue'. N.p., 2015. Web. 30 July 2015.

Abs.gov.au,. '3218.0 -  Regional Population Growth, Australia, 2013-14'. N.p., 2015. Web. 12 Aug. 2015.